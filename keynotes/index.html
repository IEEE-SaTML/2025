<!DOCTYPE html>
<html lang="en-us">
  

<head>
  <meta name="theme" content="Syna">
  <meta name="theme-version" content="v0.17.4">
  <meta name="theme-url" content="https://syna.okkur.org">
  <meta name="theme-description" content="Highly customizable open source theme for Hugo based static websites">
  <meta name="theme-author" content="Okkur Labs">
  <meta name="theme-author-url" content="https://about.okkur.org">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="google" content="notranslate" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="description" content="Keynote 1: Malice, Models and Middlemen Michael Veale, University College London Abstract In recent years, machine learning systems have demonstrated impressive outputs, yet their robustness and overall performance remain complex issues. Criminal enterprises, however, are less concerned with certain types of errors, as they can externalize the cost of these errors onto their victims. This dynamic is evident in areas like spam and fraud, where automated systems have long been prevalent.">
  <meta property="og:title" content="Keynotes" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://satml.org/2025/keynotes/" /><meta property="article:section" content="" />
<meta property="article:published_time" content="2022-08-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-11-05T09:47:55+01:00" />


  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Keynotes &amp;middot; IEEE SaTML 2025" />
  <meta name="twitter:description" content="Keynote 1: Malice, Models and Middlemen Michael Veale, University College London Abstract In recent years, machine learning systems have demonstrated impressive outputs, yet their robustness and overall performance remain complex issues. Criminal enterprises, however, are less concerned with certain types of errors, as they can externalize the cost of these errors onto their victims. This dynamic is evident in areas like spam and fraud, where automated systems have long been prevalent.">
  <meta name="twitter:url" content="https://satml.org/2025/keynotes/" />
        <meta property="og:image" content="">
        <meta name="twitter:image" content="">
  <meta name="author" content="IEEE SaTML 2024">

  <meta name="generator" content="Hugo 0.122.0">

  <title>Keynotes &middot; IEEE SaTML 2025</title>

  <!-- Theme Styles -->
  <style>
.mx-0 {
  margin-left: 0 !important;
  margin-right: 0 !important; }

 
@-ms-viewport {
  width: device-width; }

html {
  box-sizing: border-box;
  -ms-overflow-style: scrollbar; }

*,
*::before,
*::after {
  box-sizing: inherit; }

.container {
  width: 100%;
  padding-right: 15px;
  padding-left: 15px;
  margin-right: auto;
  margin-left: auto;
  max-width: 540px;
  max-width: 720px;
  max-width: 960px;
  max-width: 1140px; }

.container-fluid {
  width: 100%;
  padding-right: 15px;
  padding-left: 15px;
  margin-right: auto;
  margin-left: auto; }

.row {
  display: flex;
  flex-wrap: wrap;
  margin-right: -15px;
  margin-left: -15px; }

.no-gutters {
  margin-right: 0;
  margin-left: 0; }
  .no-gutters > .col,
  .no-gutters > [class*="col-"] {
    padding-right: 0;
    padding-left: 0; }

.col-1, .col-2, .col-3, .col-4, .col-5, .col-6, .col-7, .col-8, .col-9, .col-10, .col-11, .col-12, .col,
.col-auto {
  position: relative;
  width: 100%;
  min-height: 1px;
  padding-right: 15px;
  padding-left: 15px; }

.col {
  flex-basis: 0;
  flex-grow: 1;
  max-width: 100%; }

.col-auto {
  flex: 0 0 auto;
  width: auto;
  max-width: none; }

.col-1 {
  flex: 0 0 8.33333%;
  max-width: 8.33333%; }

.col-2 {
  flex: 0 0 16.66667%;
  max-width: 16.66667%; }

.col-3 {
  flex: 0 0 25%;
  max-width: 25%; }

.col-4 {
  flex: 0 0 33.33333%;
  max-width: 33.33333%; }

.col-5 {
  flex: 0 0 41.66667%;
  max-width: 41.66667%; }

.col-6 {
  flex: 0 0 50%;
  max-width: 50%; }

.col-7 {
  flex: 0 0 58.33333%;
  max-width: 58.33333%; }

.col-8 {
  flex: 0 0 66.66667%;
  max-width: 66.66667%; }

.col-9 {
  flex: 0 0 75%;
  max-width: 75%; }

.col-10 {
  flex: 0 0 83.33333%;
  max-width: 83.33333%; }

.col-11 {
  flex: 0 0 91.66667%;
  max-width: 91.66667%; }

.col-12 {
  flex: 0 0 100%;
  max-width: 100%; }

.order-first {
  order: -1; }

.order-last {
  order: 13; }

.order-0 {
  order: 0; }

.order-1 {
  order: 1; }

.order-2 {
  order: 2; }

.order-3 {
  order: 3; }

.order-4 {
  order: 4; }

.order-5 {
  order: 5; }

.order-6 {
  order: 6; }

.order-7 {
  order: 7; }

.order-8 {
  order: 8; }

.order-9 {
  order: 9; }

.order-10 {
  order: 10; }

.order-11 {
  order: 11; }

.order-12 {
  order: 12; }

.offset-1 {
  margin-left: 8.33333%; }

.offset-2 {
  margin-left: 16.66667%; }

.offset-3 {
  margin-left: 25%; }

.offset-4 {
  margin-left: 33.33333%; }

.offset-5 {
  margin-left: 41.66667%; }

.offset-6 {
  margin-left: 50%; }

.offset-7 {
  margin-left: 58.33333%; }

.offset-8 {
  margin-left: 66.66667%; }

.offset-9 {
  margin-left: 75%; }

.offset-10 {
  margin-left: 83.33333%; }

.offset-11 {
  margin-left: 91.66667%; }

.d-none {
  display: none !important; }

.d-inline {
  display: inline !important; }

.d-inline-block {
  display: inline-block !important; }

.d-block {
  display: block !important; }

.d-table {
  display: table !important; }

.d-table-row {
  display: table-row !important; }

.d-table-cell {
  display: table-cell !important; }

.d-flex {
  display: flex !important; }

.d-inline-flex {
  display: inline-flex !important; }

@media print {
  .d-print-none {
    display: none !important; }
  .d-print-inline {
    display: inline !important; }
  .d-print-inline-block {
    display: inline-block !important; }
  .d-print-block {
    display: block !important; }
  .d-print-table {
    display: table !important; }
  .d-print-table-row {
    display: table-row !important; }
  .d-print-table-cell {
    display: table-cell !important; }
  .d-print-flex {
    display: flex !important; }
  .d-print-inline-flex {
    display: inline-flex !important; } }

.flex-row {
  flex-direction: row !important; }

.flex-column {
  flex-direction: column !important; }

.flex-row-reverse {
  flex-direction: row-reverse !important; }

.flex-column-reverse {
  flex-direction: column-reverse !important; }

.flex-wrap {
  flex-wrap: wrap !important; }

.flex-nowrap {
  flex-wrap: nowrap !important; }

.flex-wrap-reverse {
  flex-wrap: wrap-reverse !important; }

.flex-fill {
  flex: 1 1 auto !important; }

.flex-grow-0 {
  flex-grow: 0 !important; }

.flex-grow-1 {
  flex-grow: 1 !important; }

.flex-shrink-0 {
  flex-shrink: 0 !important; }

.flex-shrink-1 {
  flex-shrink: 1 !important; }

.justify-content-start {
  justify-content: flex-start !important; }

.justify-content-end {
  justify-content: flex-end !important; }

.justify-content-center {
  justify-content: center !important; }

.justify-content-between {
  justify-content: space-between !important; }

.justify-content-around {
  justify-content: space-around !important; }

.align-items-start {
  align-items: flex-start !important; }

.align-items-end {
  align-items: flex-end !important; }

.align-items-center {
  align-items: center !important; }

.align-items-baseline {
  align-items: baseline !important; }

.align-items-stretch {
  align-items: stretch !important; }

.align-content-start {
  align-content: flex-start !important; }

.align-content-end {
  align-content: flex-end !important; }

.align-content-center {
  align-content: center !important; }

.align-content-between {
  align-content: space-between !important; }

.align-content-around {
  align-content: space-around !important; }

.align-content-stretch {
  align-content: stretch !important; }

.align-self-auto {
  align-self: auto !important; }

.align-self-start {
  align-self: flex-start !important; }

.align-self-end {
  align-self: flex-end !important; }

.align-self-center {
  align-self: center !important; }

.align-self-baseline {
  align-self: baseline !important; }

.align-self-stretch {
  align-self: stretch !important; }
</style>

      <link href="https://satml.org/2025/style.min.472d4a9445d354508a7db6c12c2d573ba667fda53a53dbdb13f34caf1e488dbf.css" rel="stylesheet">
      <link rel="shortcut icon" type="image/x-icon" href="favicon.iso">
      <link rel="icon" sizes="16x16 32x32" type="image/x-icon" href="https://satml.org/2025/favicon.iso">
      <link rel="icon" href="https://satml.org/2025/favicon.png">
      <link rel="apple-touch-icon-precomposed" href="https://satml.org/2025/favicon.png">
      <link rel="icon" type="image/svg+xml" href="https://satml.org/2025/favicon.svg">

  <script>
    window.syna = {
      
    };
  </script>
  <script src="https://satml.org/2025/scripts/syna-head.min.18217968b89d21d76154b5375b2ae039e539f6bc86a47e9903d40f0af2bd5d83.js"></script>
      <link rel='stylesheet' href='https://satml.org/2025/css/custom.css'></head>
<body class="bg-secondary">
    <!-- Navigation --><nav class="overlay fragment navbar navbar-expand-lg py-2 scroll-spy bg-light navbar-light" id="nav" role="navigation">
  <div class="container">
      <a class="navbar-brand py-0" href="https://satml.org/2025/#">IEEE SaTML 2025</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="navbar-collapse justify-content-end collapse show" id="navbarCollapse">
      <ul class="navbar-nav"><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/"
                >
                Home
              </a>
              
            </li><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/participate-cfp"
                >
                Call for Papers
              </a>
              
            </li><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/program"
                >
                Program
              </a>
              
            </li><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/competitions"
                >
                Competitions
              </a>
              
            </li><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/attend"
                >
                Attending
              </a>
              
            </li><li class="nav-item ">
              <a
                  class="nav-link"
                
                  href="https://satml.org/2025/organization"
                >
                Organization
              </a>
              
            </li><li class="nav-item dropdown">
              <a
                  class="nav-link dropdown-toggle"
                
                  id="navbarDropdown"
                  role="button"
                  data-toggle="dropdown"
                  aria-haspopup="true"
                  aria-expanded="false"
                  href="#"
                >
                Past Editions
              </a>
              
              <style>
              .nav-link.dropdown-toggle::after {
                display: none !important;
              }
            </style>
              <div class="dropdown-menu" style="background-color: #FFFFFF;" aria-labelledby="navbarDropdown">
                
                  <a class="dropdown-item " href="https://satml.org/2023/">2023</a>
                
                  <a class="dropdown-item " href="https://satml.org/2024/">2024</a>
                
              </div>
              
            </li>
      </ul>
    </div>
  </div>
  <div class="d-none d-lg-block pl-auto">
    <a class="btn" href="mailto:contact@satml.org" role="button" title="">
      <i class="fa fa-envelope mr-2"></i>
      
    </a>
  </div>
    <div class="d-none d-lg-block pl-auto">
      <a class="btn" href="https://twitter.com/satml_conf" role="button" title="">
        <i class="fab fa-twitter mr-2"></i>
        
      </a>
    </div>
</nav>

<div class="scroll-to-top bg-primary has-font-icon"
  title="Back to top"
  ><i class="fas fa-angle-up"></i><span class="sr-only">Back to top</span>
</div>

<!-- Content -->
<section id="content" class="fragment content-fragment">
    <div class="container-fluid bg-light overlay">
    <div class="container py-5 overlay">
<div class="row">
      <article class="col-md-12">
  <div class="title-container row mx-0">
    <div class="title col px-0 text-left text-body">
      <h2>Keynote Talks</h2>
    </div>
  </div><div class="subtitle-container row mx-0">
    <div class="subtitle col pt-4 pb-0 px-0 text-left text-body">
      <h5></h5>
    </div>
  </div>
<div class="content-body col-12 content px-0 text-body"><p><a class="anchor" name="keynote1"></a></p>
<div class="row keynotes-list">
    <div class="col-md-2 text-left">
    <img src="../images/2025/michael.jpg">
    </div>
    <div class="col-md-10">
    <h4>Keynote 1: <br> Malice, Models and Middlemen</h4>
    <a href="https://profiles.ucl.ac.uk/53958">Michael Veale</a>,
    <i>University College London</i>
    </div>
</div>
<h5 id="abstract">Abstract</h5>
<p>In recent years, machine learning systems have demonstrated impressive outputs, yet their robustness and overall performance remain complex issues. Criminal enterprises, however, are less concerned with certain types of errors, as they can externalize the cost of these errors onto their victims. This dynamic is evident in areas like spam and fraud, where automated systems have long been prevalent. As criminal enterprises begin deploying machine learning systems for malicious purposes, it becomes increasingly challenging to directly identify and stop these actors. Disrupting their activities requires targeting the intermediaries that connect criminals to their victims, including communication providers, cloud compute services, operating systems providing local compute like smartphone providers, model marketplaces like Hugging Face and GitHub, and content platforms like social media services. The safety and trustworthiness of AI will likely depend on the cooperation and governance mechanisms established by these intermediaries.</p>
<p>Legal regimes and technical governance methods will play a significant role in this landscape. This involves monitoring cloud computing, controlling operations on operating systems, removing controversial dual-use models from online repositories, and requiring platforms to manage content decisions at scale. Each of these measures presents challenges, and achieving the right balance is complex. In this keynote, I will explore the role of intermediaries, examine emerging governance practices, and highlight the core tensions, difficulties, and opportunities in this evolving space.</p>
<h5 id="speaker-bio">Speaker Bio</h5>
<p>Michael Veale is Associate Professor in Digital Rights and Regulation and Vice-Dean (Education Innovation) at the Faculty of Laws, University College London (UCL), and Fellow at the Institute for Information Law, University of Amsterdam. His research focusses on how to understand and address challenges of power and justice that digital technologies and their users create and exacerbate, in areas such as privacy-enhancing technologies and machine learning. Veale has advised a wide variety of actors across the world on these issues, and his work is cited by hundreds of public policy players including courts, regulators, governments, legislatures, civil society and business, as well as thousands of academics. He sits on the advisory councils for the Open Rights Group and Foxglove, the Panel of Expert of the Digital Freedom Fund, and the Technology Advisory Panel for the Information Commissioner’s Office. He holds a PhD in the governance of machine learning from the Faculty of Engineering, UCL, as well as degrees from LSE and U Maastricht.</p>
<p><a class="anchor" name="keynote2"></a></p>
<div class="row keynotes-list">
    <div class="col-md-2">
    <img src="../images/2025/kamalika2.jpg">
    </div>
    <div class="col-md-10">
    <h4>Keynote 2: <br> The Science of Empirical Privacy Measurement: Memorization and Beyond</h4>
    <a href="https://cseweb.ucsd.edu/~kamalika/">Kamalika Chaudhuri</a>, <i>University of California San Diego</i>
    </div>
</div>
<h5 id="abstract-1">Abstract</h5>
<p>Since Fredriksson et al (2014), a body of work has emerged on the empirical measurement of privacy leakage, both from machine learning models and in other settings. In this talk, I will describe some recent advancements on this topic. First, we will look at memorization in vision encoder models, and propose a principled measurement of &ldquo;deja vu memorization&rdquo;; we will show how to scale it to off-the-shelf vision encoder models. Next, we will go beyond memorization, and talk about how privacy and memorization may be decoupled in more complicated settings.</p>
<h5 id="speaker-bio-1">Speaker Bio</h5>
<p>Kamalika Chaudhuri is a Director, Research Scientist at FAIR in Meta and an adjunct professor at University of California, San Diego. She was formerly a full professor at University of California, San Diego. She received a Bachelor of Technology degree in Computer Science and Engineering in 2002 from Indian Institute of Technology, Kanpur, and a PhD in Computer Science from University of California at Berkeley in 2007. She received an NSF CAREER Award in 2013 and a Hellman Faculty Fellowship in 2012. She has served as the program co-chair for AISTATS 2019 and ICML 2019, and as the General Chair for ICML 2022.</p>
<p><a class="anchor" name="keynote3"></a></p>
<div class="row keynotes-list">
    <div class="col-md-2 text-left">
    <img src="../images/2025/matt.jpg">
    </div>
    <div class="col-md-10">
    <h4>Keynote 3: <br> Artificial Intelligence: Should you trust it?</h4>
    <a href="https://www.darpa.mil/staff/dr-matt-turek">Matt Turek</a>, <i>Defense Advanced Research Agency</i>
    </div>
</div>
<h5 id="abstract-2">Abstract</h5>
<p>We have seen significant progress in Artificial Intelligence (AI) over the last ten years, predominantly driven by dramatic advances in machine learning and particularly deep learning. Society is realizing the benefits across a wide range of application domains. However, within the military, the consequence of making a wrong decision based on AI could be catastrophic. And the United States Department of Defense must defend against nation-state level adversaries with significant resources, the ability to create deception, and the desire to change our way of life. The US’s Defense Advanced Research Projects Agency (DARPA) is funding research in trustworthy AI technologies and systems that can be trusted to perform as expected despite the efforts of sophisticated adversaries. In this presentation, I will discuss research efforts in AI that we can trust with our (and warfighters’) lives and explore DARPA-funded advances that appear promising toward reaching the goal of trustworthy AI.</p>
<h5 id="speaker-bio-2">Speaker Bio</h5>
<p>Matt Turek is the deputy office director for the Defense Advanced Research
Agency’s (DARPA) Information Innovation Office (I2O), where he provides
technical leadership and works with program managers to envision, create, and
transition capabilities that ensure enduring information advantage for the United States and its allies. Previously, Turek served as I2O’s acting deputy director and as a program manager for AI-related programs, including Explainable AI, Machine Common Sense, Media Forensics, and Semantic Forensics. He joined DARPA from Kitware, Inc., where he led a team developing computer vision technologies. Prior to that role, he was at GE Global Research conducting research in medical imaging and industrial inspection.</p>
</div>
    </article>
  </div>
    </div>
    </div>
</section>


<!-- Copyright -->
<footer class="overlay fragment container-fluid bg-light" id="copyright">
  <div class="container">
    <div class="row py-3">
      <div class="col-md">
        <div class="row mx-0 my-2 justify-content-center text-center text-lg-none text-black-50">
          <div class="row mx-0 mr-lg-auto justify-content-center">
              <div class="col-auto copyright-notice"></div>
          </div>
        </div>
      </div>
        <div class="col-auto mx-auto">
          <div class="row mx-0 navbar-text text-center dark">This conference follows the<a
            href="https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/ieee_code_of_conduct.pdf"
            target="_blank" class="ml-1">IEEE Code of Conduct</a> ·<a href="https://www.ieee.org/security-privacy.html" target="_blank" class="ml-1">IEEE Privacy Policy</a> ·<a href="https://satml.org/2025/statements" class="ml-1">Conference Statements</a>
            
          </div>
        </div>
        <div class="col-md">
          <div class="row mx-0 my-2 justify-content-center">
            <ul class="nav ml-lg-auto">
                <li class="nav-item">
                  <a class="nav-link py-0" href="https://satml.org/2025/#"
                  
                    class="anchor"
                  ></a>
                </li>
            </ul>
          </div>
        </div>
    </div>
  </div>
</footer>
<div id="react"></div>

    <!-- Theme Code -->
      <script async defer src="https://satml.org/2025/scripts/syna-main.min.e55fd8c5af086da9842b94023904a4927a065797faf15b6c8279662389baa192.js"></script>
      <script async defer src="https://satml.org/2025/scripts/syna-content.min.7e70b7046dc64796f31315f23757983222bc7a81353b1cc191eaf95b96d5e98d.js"></script>
      <link rel='stylesheet' href='https://satml.org/2025/css/custom.css'>
  </body>
</html>
