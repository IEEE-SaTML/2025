<div class="cd-schedule-modal__event-info fw-bold">
	<div>
		<h1 style="font-weight: bold;">Title:</h1> Audits and Accountability in the Age of 'Artificial Intelligence'
		<br>
		<br>
		<h1 style="font-weight: bold;">Abstract:</h1> When AI systems fall short of articulated expectations, people get
		hurt.
		<br>
		<br>
		In order to hold those who build AI systems accountable for the
		consequences of their actions, we need to operationalize a system for
		<i>auditing</i>. AI audits have for years been part of the
		conversation in the context of online platforms but are now just
		beginning to emerge as a mode of external oversight and evaluation
		regarding the deployment of a broader range of "automated decision
		systems" (ADS) and other AI-branded products, including the latest crop
		of "generative AI" models. As AI auditing makes its way into critical
		policy proposals as a primary mechanism for algorithmic accountability,
		we must think critically about the necessary technical and institutional
		infrastructure required for this form of oversight to be successful.
		<br>
		<br>
		<h1 style="font-weight: bold;">Biography:</h1> Deborah Raji is a Mozilla
		fellow and CS PhD student at University of California, Berkeley, who is
		interested in questions on algorithmic auditing and evaluation. In the
		past, she worked closely with the Algorithmic Justice League initiative
		to highlight bias in deployed AI products. She has also worked with
		Google ºs Ethical AI team and been a research fellow at the Partnership
		on AI and AI Now Institute at New York University working on various
		projects to operationalize ethical considerations in ML engineering
		practice. Recently, she was named to Forbes 30 Under 30 and MIT Tech
		Review 35 Under 35 Innovators.

		<br>
		<br>

		<img src="/images/2024/people/Deborah-Raji.jpg" class="portfolio-image
		img-fluid" alt="">

	</div>



</div>